---
layout: post
title: Install Hadoop 2.5.0 on Arch Linux
excerpt: Steps of installing Hadoop 2.5.0 on Arch Linux
categories:
  -  Linux
tags:
  -  [Linux, Hadoop, Arch Linux]
---
<p>
This post is roughly based on the <a href="http://hadoop.apache.org/docs/r2.5.0/hadoop-project-dist/hadoop-common/SingleCluster.html">Apache Hadoop 2.5.0 documentation of Single
Node Cluster</a>.
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Preparation</h2>
<div class="outline-text-2" id="text-1">
<p>
Before installing Hadoop, we should make sure that <code>ssh</code>, <code>rsync</code> and <code>OpenJDK</code>
are already installed on the computer. According to <a href="http://wiki.apache.org/hadoop/HadoopJavaVersions">HadoopJavaVersions</a>, OpenJDK
7, which is offered by Arch Official Repository, is good to work with Hadoop.
However, there is a minor problem during recent <code>java-common</code>'s upgrading from
1.6 to 1.7, which causes the problem that the default jvm might not be correctly
configured. Run
</p>
<div class="org-src-container">

<pre class="src src-sh">archlinux-java status
</pre>
</div>
<p>
to see whether the default jvm has already been chosen. If not, Run
</p>
<div class="org-src-container">

<pre class="src src-sh">archlinux-java fix
</pre>
</div>
<p>
to fix it.
</p>

<p>
We also want a dedicated user and group for Hadoop. This is quite easy:
</p>
<div class="org-src-container">

<pre class="src src-sh">sudo groupadd hadoop
sudo useradd -m -g hadoop hduser
</pre>
</div>

<p>
OK, done. Let's go ahead and install Hadoop.
</p>

<p>
Note: I did try the instructions on <a href="https://wiki.archlinux.org/index.php/Hadoop">Hadoop ArchWiki Page</a> and installed the
<code>Hadoop</code> package from AUR. But the wiki page seems out-of-date and it is hard to
configure the AUR package for pseudo-distributed mode since I didn't manage to
find useful documentation about that.
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Install Hadoop</h2>
<div class="outline-text-2" id="text-2">
</div><div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> Download the Distribution</h3>
<div class="outline-text-3" id="text-2-1">
<p>
First download Hadoop 2.5.0 distribution from <a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/">Apache Download Mirrors</a>. Extract
it to <code>hadoop-2.5.0</code> directory and move it to a directory you like. I moved it
to <code>/usr/local/</code>, and ran the following command(may need root privilege):
</p>
<div class="org-src-container">

<pre class="src src-sh">ln -s /usr/local/hadoop-2.5.0 /usr/local/hadoop
chown -R hduser:hadoop /usr/local/hadoop-2.5.0
</pre>
</div>
</div>
</div>
<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> Change Environment Variables</h3>
<div class="outline-text-3" id="text-2-2">
<p>
The most important environment variable is <code>JAVA_HOME</code> in
<code>/usr/local/hadoop/etc/hadoop/hadoop-env.sh</code>. Usually changing it to
<code>/usr/lib/jvm/default</code> would be enough for Arch Linux users.
</p>

<p>
The following change is not mandatory, but it may simplify our typing&#x2026;I Added
these lines to the initial script of my favorite shell(as user <code>hduser</code>):
</p>
<div class="org-src-container">

<pre class="src src-sh"><span style="color: #DFAF8F;">HADOOP_PREFIX</span>=/usr/local/hadoop
<span style="color: #DFAF8F;">PATH</span>=$<span style="color: #DFAF8F;">PATH</span>:${<span style="color: #DFAF8F;">HADOOP_PREFIX</span>}/bin:${<span style="color: #DFAF8F;">HADOOP_PREFIX</span>}/sbin
</pre>
</div>
</div>
</div>
<div id="outline-container-sec-2-3" class="outline-3">
<h3 id="sec-2-3"><span class="section-number-3">2.3</span> Standalone Mode</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Now Hadoop should work in a non-distributed mode. The following commands are
based on <a href="http://hadoop.apache.org/docs/r2.5.0/hadoop-project-dist/hadoop-common/SingleCluster.html">Apache Hadoop Documentation</a>.
</p>
<div class="org-src-container">

<pre class="src src-sh">mkdir input
cp ${<span style="color: #DFAF8F;">HADOOP_PREFIX</span>}/etc/hadoop/*.xml input
hadoop jar ${<span style="color: #DFAF8F;">HADOOP_PREFIX</span>}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar grep input output <span style="color: #CC9393;">'dfs[a-z.]+'</span>
cat output/*
</pre>
</div>
<p>
The following sections are only essential for the pseudo-distributed operation.
</p>
</div>
</div>
<div id="outline-container-sec-2-4" class="outline-3">
<h3 id="sec-2-4"><span class="section-number-3">2.4</span> Setup Paraphraseless SSH</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Now ssh onto localhost as <code>hduser</code>, then
</p>
<div class="org-src-container">

<pre class="src src-sh">ssh-keygen -P <span style="color: #CC9393;">''</span>
cat $<span style="color: #DFAF8F;">HOME</span>/.ssh/id_rsa.pub &gt;&gt; $<span style="color: #DFAF8F;">HOME</span>/.ssh/authorized_keys
</pre>
</div>
</div>
</div>
<div id="outline-container-sec-2-5" class="outline-3">
<h3 id="sec-2-5"><span class="section-number-3">2.5</span> Configuration for Pseudo-Distributed Mode</h3>
<div class="outline-text-3" id="text-2-5">
<p>
I added the following lines to <code>${HADOOP_PREFIX}/etc/hadoop/core-site.xml</code>:
</p>
<div class="org-src-container">

<pre class="src src-xml">&lt;<span style="color: #93E0E3;">configuration</span>&gt;
  &lt;<span style="color: #93E0E3;">property</span>&gt;
    &lt;<span style="color: #93E0E3;">name</span>&gt;fs.defaultFS&lt;/<span style="color: #93E0E3;">name</span>&gt;
    &lt;<span style="color: #93E0E3;">value</span>&gt;hdfs://localhost:9000&lt;/<span style="color: #93E0E3;">value</span>&gt;
  &lt;/<span style="color: #93E0E3;">property</span>&gt;
  &lt;<span style="color: #93E0E3;">property</span>&gt;
    &lt;<span style="color: #93E0E3;">name</span>&gt;hadoop.tmp.dir&lt;/<span style="color: #93E0E3;">name</span>&gt;
    &lt;<span style="color: #93E0E3;">value</span>&gt;/home/hduser/hdfs&lt;/<span style="color: #93E0E3;">value</span>&gt;
  &lt;/<span style="color: #93E0E3;">property</span>&gt;
&lt;/<span style="color: #93E0E3;">configuration</span>&gt;
</pre>
</div>

<p>
The <code>hadoop.tmp.dir</code> defaults to <code>/tmp/hadoop-${user.name}</code>. I changed it
because the contents under <code>/tmp</code> would be removed on every reboot, which is not
I want. Then add these lines to <code>${HADOOP_PREFIX}/etc/hadoop/hdfs-site.xml</code>:
</p>
<div class="org-src-container">

<pre class="src src-xml">&lt;<span style="color: #93E0E3;">configuration</span>&gt;
  &lt;<span style="color: #93E0E3;">property</span>&gt;
    &lt;<span style="color: #93E0E3;">name</span>&gt;dfs.replication&lt;/<span style="color: #93E0E3;">name</span>&gt;
    &lt;<span style="color: #93E0E3;">value</span>&gt;1&lt;/<span style="color: #93E0E3;">value</span>&gt;
  &lt;/<span style="color: #93E0E3;">property</span>&gt;
&lt;/<span style="color: #93E0E3;">configuration</span>&gt;
</pre>
</div>

<p>
Then the following commands from the <a href="http://hadoop.apache.org/docs/r2.5.0/hadoop-project-dist/hadoop-common/SingleCluster.html">Apache Hadoop Documentation</a> should work.
</p>
<div class="org-src-container">

<pre class="src src-sh">hdfs namenode -format
start-dfs.sh
hdfs dfs -mkdir /user
hdfs dfs -mkdir /user/hduser
hdfs dfs -put ${<span style="color: #DFAF8F;">HADOOP_PREFIX</span>}/etc/hadoop input
hadoop jar ${<span style="color: #DFAF8F;">HADOOP_PREFIX</span>}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar grep input output <span style="color: #CC9393;">'dfs[a-z.]+'</span>
hdfs dfs -get output output
cat output/*
stop-dfs.sh
</pre>
</div>
</div>
</div>
</div>
